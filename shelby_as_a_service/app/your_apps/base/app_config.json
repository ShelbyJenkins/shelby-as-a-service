{
    "app": {
        "app_name": "base",
        "enabled_sprites": [
            "webui_sprite"
        ],
        "enabled_extensions": [],
        "disabled_extensions": []
    },
    "context_index": {
        "data_domains": [
            {
                "NAME": "A default topi",
                "DESCRIPTION": "A default description",
                "data_sources": [
                    {
                        "NAME": "A default source",
                        "DESCRIPTION": "A default description",
                        "data_source_api_url_format": null,
                        "data_source_filter_url": null,
                        "data_source_url": null,
                        "default_doc_loader": "generic_web_scraper",
                        "default_database_provider": "Local Files as a Database",
                        "batch_update_enabled": true
                    }
                ],
                "default_database_provider": "Local Files as a Database",
                "batch_update_enabled": true
            }
        ],
        "default_database_provider": "Local Files as a Database",
        "update_enabled": true
    },
    "webui_sprite": {
        "default_local_app_enabled": false,
        "default_local_app_name": null,
        "local_message_start": "Running request... relax, chill, and vibe a minute.",
        "local_message_end": "Generated by: gpt-4. Memory not enabled. Has no knowledge of past or current queries. For code see https://github.com/shelby-as-a-service/shelby-as-a-service.",
        "current_ui_view_name": "Context Index",
        "gradio_ui": {
            "default_local_app_enabled": false,
            "default_local_app_name": null,
            "local_message_start": "Running request... relax, chill, and vibe a minute.",
            "local_message_end": "Generated by: gpt-4. Memory not enabled. Has no knowledge of past or current queries. For code see https://github.com/shelby-as-a-service/shelby-as-a-service.",
            "current_ui_view_name": "Main Chat",
            "main_chat_view": {
                "current_agent_name": "vanillallm_agent",
                "current_agent_ui_name": "VanillaLLM Agent",
                "vanillallm_agent": {
                    "agent_select_status_message": "EZPZ",
                    "llm_service": {
                        "llm_provider": "openai_llm",
                        "model_token_utilization": 0.5,
                        "openai_llm": {
                            "current_model_name": "gpt-3.5-turbo",
                            "available_models": {
                                "gpt-4": {
                                    "MODEL_NAME": "gpt-4",
                                    "TOKENS_MAX": 8192,
                                    "COST_PER_K": 0.06,
                                    "TOKENS_PER_MESSAGE": 3,
                                    "TOKENS_PER_NAME": 1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                },
                                "gpt-4-32k": {
                                    "MODEL_NAME": "gpt-4-32k",
                                    "TOKENS_MAX": 32768,
                                    "COST_PER_K": 0.06,
                                    "TOKENS_PER_MESSAGE": 3,
                                    "TOKENS_PER_NAME": 1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                },
                                "gpt-3.5-turbo": {
                                    "MODEL_NAME": "gpt-3.5-turbo",
                                    "TOKENS_MAX": 4096,
                                    "COST_PER_K": 0.03,
                                    "TOKENS_PER_MESSAGE": 4,
                                    "TOKENS_PER_NAME": -1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                },
                                "gpt-3.5-turbo-16k": {
                                    "MODEL_NAME": "gpt-3.5-turbo-16k",
                                    "TOKENS_MAX": 16384,
                                    "COST_PER_K": 0.03,
                                    "TOKENS_PER_MESSAGE": 3,
                                    "TOKENS_PER_NAME": 1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                }
                            }
                        }
                    }
                },
                "ceq_agent": {
                    "enabled_data_domains": [
                        "all"
                    ],
                    "context_to_response_ratio": 0.5,
                    "retrieval_agent": {
                        "doc_max_tokens": 1400.0,
                        "docs_max_count": 4.0,
                        "topic_constraint_enabled": false,
                        "keyword_generator_enabled": false,
                        "doc_relevancy_check_enabled": false,
                        "embedding_service": {
                            "embedding_provider": "openai_embedding",
                            "openai_embedding": {
                                "current_model_name": "text-embedding-ada-002",
                                "available_models": {
                                    "text-embedding-ada-002": {
                                        "MODEL_NAME": "text-embedding-ada-002",
                                        "TOKENS_MAX": 8192,
                                        "COST_PER_K": 0.0001
                                    }
                                }
                            }
                        },
                        "database_service": {
                            "database_provider": "pinecone_database",
                            "retrieve_n_docs": 6,
                            "local_filestore_database": {
                                "max_response_tokens": 1
                            },
                            "pinecone_database": {
                                "index_env": "us-central1-gcp",
                                "index_name": "shelby-as-a-service",
                                "vectorstore_dimension": 1536,
                                "vectorstore_upsert_batch_size": 20,
                                "vectorstore_metric": "cosine",
                                "vectorstore_pod_type": "p1",
                                "preprocessor_min_length": 150,
                                "text_splitter_goal_length": 750,
                                "text_splitter_overlap_percent": 15,
                                "retrieve_n_docs": 5,
                                "indexed_metadata": [
                                    "data_domain_name",
                                    "data_source_name",
                                    "doc_type",
                                    "target_type",
                                    "date_indexed"
                                ]
                            }
                        }
                    },
                    "llm_service": {
                        "llm_provider": "openai_llm",
                        "model_token_utilization": 0.5,
                        "openai_llm": {
                            "current_model_name": "gpt-3.5-turbo",
                            "available_models": {
                                "gpt-4": {
                                    "MODEL_NAME": "gpt-4",
                                    "TOKENS_MAX": 8192,
                                    "COST_PER_K": 0.06,
                                    "TOKENS_PER_MESSAGE": 3,
                                    "TOKENS_PER_NAME": 1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                },
                                "gpt-4-32k": {
                                    "MODEL_NAME": "gpt-4-32k",
                                    "TOKENS_MAX": 32768,
                                    "COST_PER_K": 0.06,
                                    "TOKENS_PER_MESSAGE": 3,
                                    "TOKENS_PER_NAME": 1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                },
                                "gpt-3.5-turbo": {
                                    "MODEL_NAME": "gpt-3.5-turbo",
                                    "TOKENS_MAX": 4096,
                                    "COST_PER_K": 0.03,
                                    "TOKENS_PER_MESSAGE": 4,
                                    "TOKENS_PER_NAME": -1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                },
                                "gpt-3.5-turbo-16k": {
                                    "MODEL_NAME": "gpt-3.5-turbo-16k",
                                    "TOKENS_MAX": 16384,
                                    "COST_PER_K": 0.03,
                                    "TOKENS_PER_MESSAGE": 3,
                                    "TOKENS_PER_NAME": 1,
                                    "frequency_penalty": 0,
                                    "max_tokens": 4096,
                                    "presence_penalty": 0,
                                    "stream": true,
                                    "temperature": 1,
                                    "top_p": 1
                                }
                            }
                        }
                    }
                }
            },
            "context_index_view": {
                "current_data_domain_name": "A default topi",
                "current_data_source_name": "A default source",
                "ingest_agent": {
                    "database_provider": "local_filestore_database",
                    "doc_loading_provider": "generic_web_scraper",
                    "doc_loading_service": {
                        "doc_loading_provider": "generic_web_scraper",
                        "generic_web_scraper": {
                            "agent_select_status_message": "Search index to find docs related to request.",
                            "continue_on_failue": true
                        }
                    },
                    "database_service": {
                        "database_provider": "pinecone_database",
                        "retrieve_n_docs": 6,
                        "local_filestore_database": {
                            "max_response_tokens": 1
                        },
                        "pinecone_database": {
                            "index_env": "us-central1-gcp",
                            "index_name": "shelby-as-a-service",
                            "vectorstore_dimension": 1536,
                            "vectorstore_upsert_batch_size": 20,
                            "vectorstore_metric": "cosine",
                            "vectorstore_pod_type": "p1",
                            "preprocessor_min_length": 150,
                            "text_splitter_goal_length": 750,
                            "text_splitter_overlap_percent": 15,
                            "retrieve_n_docs": 5,
                            "indexed_metadata": [
                                "data_domain_name",
                                "data_source_name",
                                "doc_type",
                                "target_type",
                                "date_indexed"
                            ]
                        }
                    }
                },
                "database_service": {
                    "database_provider": "pinecone_database",
                    "retrieve_n_docs": 6,
                    "local_filestore_database": {
                        "max_response_tokens": 1
                    },
                    "pinecone_database": {
                        "index_env": "us-central1-gcp",
                        "index_name": "shelby-as-a-service",
                        "vectorstore_dimension": 1536,
                        "vectorstore_upsert_batch_size": 20,
                        "vectorstore_metric": "cosine",
                        "vectorstore_pod_type": "p1",
                        "preprocessor_min_length": 150,
                        "text_splitter_goal_length": 750,
                        "text_splitter_overlap_percent": 15,
                        "retrieve_n_docs": 5,
                        "indexed_metadata": [
                            "data_domain_name",
                            "data_source_name",
                            "doc_type",
                            "target_type",
                            "date_indexed"
                        ]
                    }
                }
            },
            "settings_view": {
                "default_local_app_enabled": false,
                "default_local_app_name": null,
                "local_message_start": "Running request... relax, chill, and vibe a minute.",
                "local_message_end": "Generated by: gpt-4. Memory not enabled. Has no knowledge of past or current queries. For code see https://github.com/shelby-as-a-service/shelby-as-a-service.",
                "current_ui_view_name": "Main Chat"
            }
        }
    }
}